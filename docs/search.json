[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Doing Bayesian Data Analysis in Julia using Turing.jl",
    "section": "",
    "text": "Kruschke began his text with, “This book explains how to actually do Bayesian data analysis, by real people (like you), for realistic data (like yours).” In the same way, this project is designed to help those real people do Bayesian data analysis. My contribution is converting Kruschke’s JAGS and Stan code for use in another probabilistic programming framework,Turing.jl, which makes it easier to fit Bayesian regression models in Julia (Ge, Xu, and Ghahramani (2018)) using a number of samplers. I also prefer plotting and data wrangling with the packages from Plots.jl(Bezanson et al. (2017)). So we’ll be using those methods, too.\nThis ebook is not meant to stand alone. It’s a supplement to the second edition of Kruschke (2015) Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Please give the source material some love.\n\n\nTo follow along with this guide, you’ll need some software. Download and install Julia by following the instructions at https://julialang.org/downloads/. The Getting Started page has in depth instructions that can help.\nYou will also need to install some packages. To install packages in Julia, you will need the Pkg package. Fortunately the Julia REPL (which stands for “read, execute, print, loop”) has a trick that allows you to access the package from within the REPL command-line. Enter the Pkg REPL by pressing ] from the Julia REPL. To get back to the Julia REPL, press backspace.\n\n\n\n\n\n\nNote\n\n\n\nFor more information on the Pkg REPL, take a look at the Julia documentation, which is available here: https://docs.julialang.org/en/v1/stdlib/Pkg/.\n\n\n\n\n\nI am just starting this project. I plan to have a complete draft including material from all the chapters in Kruschke’s text by January 2023\n\n\n\n\nBezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017. “Julia: A Fresh Approach to Numerical Computing.” SIAM Review 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nGe, Hong, Kai Xu, and Zoubin Ghahramani. 2018. “Turing: A Language for Flexible Probabilistic Inference.” In International Conference on Artificial Intelligence and Statistics, AISTATS 2018, 9-11 April 2018, Playa Blanca, Lanzarote, Canary Islands, Spain, 1682–90. http://proceedings.mlr.press/v84/ge18b.html.\n\n\nKruschke, John. 2015. Doing Bayesian Data Analysis (Second Edition). Boston: Academic Press."
  },
  {
    "objectID": "whats-in-this-book-read-this-first.html",
    "href": "whats-in-this-book-read-this-first.html",
    "title": "1  What’s in This Book (Read This First!)",
    "section": "",
    "text": "I am not a statistician and have no formal computer science background. I am in the process of learning the Julia programming language (part of the goal of this project!). I am currently a Ph.D. student in psychology. I have been mostly an R and MATLAB user and started learning Bayesian statistics around 2019. My code will likely be “bad” as I get the hang of things. I have much to learn from the Julia community and thus encourage folk to reach out with suggestions on how to improve my code. If you’d like to learn more about me, you can find my website at https://www.kiantefernandez.com/."
  },
  {
    "objectID": "whats-in-this-book-read-this-first.html#thank-you",
    "href": "whats-in-this-book-read-this-first.html#thank-you",
    "title": "1  What’s in This Book (Read This First!)",
    "section": "1.2 Thank you!",
    "text": "1.2 Thank you!\nA. Solomon Kurz really inspired this project. He has published multiple accessible introductory content on applied Bayesian analysis, complementing many of the books that taught me Bayesian statistics. I benefitted greatly from his free content. Go find him at: https://solomonkurz.netlify.com."
  },
  {
    "objectID": "introduction-credibility-models-and-parameters.html",
    "href": "introduction-credibility-models-and-parameters.html",
    "title": "2  Introduction: Credibility, Models, and Parameters",
    "section": "",
    "text": "To make Figure 2.1 we need data. We will create some synthetic data and store it in using DataFrames.jl\n\nusing DataFrames\n\nfunction expand_grid(; iters...)\n    var_names = collect(keys(iters))\n    var_itr = [1:length(x) for x in iters.data]\n    var_ix = vcat([collect(x)' for x in Iterators.product(var_itr...)]...)\n    out = DataFrame()\n    for i = 1:length(var_names)\n        out[:,var_names[i]] = collect(iters[i])[var_ix[:,i]]\n    end\n    return out\nend\n\nd = expand_grid(iteration=1:3, Possibilities=[\"A\", \"B\",\"C\", \"D\"], stage = [\"Prior\", \"Posterior\"])\n\nd2 =DataFrame(Credibility =[fill(.25,4); 0; fill(1/3,3); 0; fill(1/3,3);0;.5;0;0.5;0;.5;0;0.5;fill(0,3);1])\n\nsort!(d, [:iteration])\nd.Credibility = d2.Credibility\n\nHere we are defining a function that creates combinations and then I just bind that we the Credibility values we will use for plotting.\nWe can take a look at the top few rows of the data with the first() function.\n\nfirst(d,5)\n\n\n5 rows × 4 columnsiterationPossibilitiesstageCredibilityInt64StringStringFloat6411APrior0.2521BPrior0.2531CPrior0.2541DPrior0.2551APosterior0.0\n\n\nNow lets plot our version of Figure 2.1. To do so, we will use the Gadfly.jl package. This is my preferred plotting package because it has similar syntax to ggplot2 package in R.\n\n\n\n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n  \n    \n      \n        Possibilities\n      \n    \n  \n  \n    \n      \n        \n          \n          \n        \n        \n          \n            \n              3\n            \n          \n        \n        \n          \n            \n              2\n            \n          \n        \n        \n          \n            \n              1\n            \n          \n        \n        \n          \n            \n              A\n            \n          \n          \n            \n              B\n            \n          \n          \n            \n              C\n            \n          \n          \n            \n              D\n            \n          \n        \n        \n          \n            \n              A\n            \n          \n          \n            \n              B\n            \n          \n          \n            \n              C\n            \n          \n          \n            \n              D\n            \n          \n        \n        \n          \n            \n              A\n            \n          \n          \n            \n              B\n            \n          \n          \n            \n              C\n            \n          \n          \n            \n              D\n            \n          \n        \n        \n          \n            \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              -1.5\n            \n          \n          \n            \n              -1.0\n            \n          \n          \n            \n              -0.5\n            \n          \n          \n            \n              0.0\n            \n          \n          \n            \n              0.5\n            \n          \n          \n            \n              1.0\n            \n          \n          \n            \n              1.5\n            \n          \n          \n            \n              2.0\n            \n          \n          \n            \n              2.5\n            \n          \n          \n            \n              -1.0\n            \n          \n          \n            \n              -0.9\n            \n          \n          \n            \n              -0.8\n            \n          \n          \n            \n              -0.7\n            \n          \n          \n            \n              -0.6\n            \n          \n          \n            \n              -0.5\n            \n          \n          \n            \n              -0.4\n            \n          \n          \n            \n              -0.3\n            \n          \n          \n            \n              -0.2\n            \n          \n          \n            \n              -0.1\n            \n          \n          \n            \n              0.0\n            \n          \n          \n            \n              0.1\n            \n          \n          \n            \n              0.2\n            \n          \n          \n            \n              0.3\n            \n          \n          \n            \n              0.4\n            \n          \n          \n            \n              0.5\n            \n          \n          \n            \n              0.6\n            \n          \n          \n            \n              0.7\n            \n          \n          \n            \n              0.8\n            \n          \n          \n            \n              0.9\n            \n          \n          \n            \n              1.0\n            \n          \n          \n            \n              1.1\n            \n          \n          \n            \n              1.2\n            \n          \n          \n            \n              1.3\n            \n          \n          \n            \n              1.4\n            \n          \n          \n            \n              1.5\n            \n          \n          \n            \n              1.6\n            \n          \n          \n            \n              1.7\n            \n          \n          \n            \n              1.8\n            \n          \n          \n            \n              1.9\n            \n          \n          \n            \n              2.0\n            \n          \n          \n            \n              -1\n            \n          \n          \n            \n              0\n            \n          \n          \n            \n              1\n            \n          \n          \n            \n              2\n            \n          \n          \n            \n              -1.00\n            \n          \n          \n            \n              -0.95\n            \n          \n          \n            \n              -0.90\n            \n          \n          \n            \n              -0.85\n            \n          \n          \n            \n              -0.80\n            \n          \n          \n            \n              -0.75\n            \n          \n          \n            \n              -0.70\n            \n          \n          \n            \n              -0.65\n            \n          \n          \n            \n              -0.60\n            \n          \n          \n            \n              -0.55\n            \n          \n          \n            \n              -0.50\n            \n          \n          \n            \n              -0.45\n            \n          \n          \n            \n              -0.40\n            \n          \n          \n            \n              -0.35\n            \n          \n          \n            \n              -0.30\n            \n          \n          \n            \n              -0.25\n            \n          \n          \n            \n              -0.20\n            \n          \n          \n            \n              -0.15\n            \n          \n          \n            \n              -0.10\n            \n          \n          \n            \n              -0.05\n            \n          \n          \n            \n              0.00\n            \n          \n          \n            \n              0.05\n            \n          \n          \n            \n              0.10\n            \n          \n          \n            \n              0.15\n            \n          \n          \n            \n              0.20\n            \n          \n          \n            \n              0.25\n            \n          \n          \n            \n              0.30\n            \n          \n          \n            \n              0.35\n            \n          \n          \n            \n              0.40\n            \n          \n          \n            \n              0.45\n            \n          \n          \n            \n              0.50\n            \n          \n          \n            \n              0.55\n            \n          \n          \n            \n              0.60\n            \n          \n          \n            \n              0.65\n            \n          \n          \n            \n              0.70\n            \n          \n          \n            \n              0.75\n            \n          \n          \n            \n              0.80\n            \n          \n          \n            \n              0.85\n            \n          \n          \n            \n              0.90\n            \n          \n          \n            \n              0.95\n            \n          \n          \n            \n              1.00\n            \n          \n          \n            \n              1.05\n            \n          \n          \n            \n              1.10\n            \n          \n          \n            \n              1.15\n            \n          \n          \n            \n              1.20\n            \n          \n          \n            \n              1.25\n            \n          \n          \n            \n              1.30\n            \n          \n          \n            \n              1.35\n            \n          \n          \n            \n              1.40\n            \n          \n          \n            \n              1.45\n            \n          \n          \n            \n              1.50\n            \n          \n          \n            \n              1.55\n            \n          \n          \n            \n              1.60\n            \n          \n          \n            \n              1.65\n            \n          \n          \n            \n              1.70\n            \n          \n          \n            \n              1.75\n            \n          \n          \n            \n              1.80\n            \n          \n          \n            \n              1.85\n            \n          \n          \n            \n              1.90\n            \n          \n          \n            \n              1.95\n            \n          \n          \n            \n              2.00\n            \n          \n        \n      \n    \n  \n  \n    \n      \n        Credibility\n      \n    \n  \n  \n    \n      \n        Posterior\n      \n    \n  \n\n\n  \n    \n  \n\n\n  \n    \n      \n        Possibilities\n      \n    \n  \n  \n    \n      \n        \n          \n          \n        \n        \n          \n            \n              3\n            \n          \n        \n        \n          \n            \n              2\n            \n          \n        \n        \n          \n            \n              1\n            \n          \n        \n        \n          \n            \n              A\n            \n          \n          \n            \n              B\n            \n          \n          \n            \n              C\n            \n          \n          \n            \n              D\n            \n          \n        \n        \n          \n            \n              A\n            \n          \n          \n            \n              B\n            \n          \n          \n            \n              C\n            \n          \n          \n            \n              D\n            \n          \n        \n        \n          \n            \n              A\n            \n          \n          \n            \n              B\n            \n          \n          \n            \n              C\n            \n          \n          \n            \n              D\n            \n          \n        \n        \n          \n            \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n              \n              \n                \n              \n              \n                \n              \n            \n            \n              \n                \n                \n              \n              \n                \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                  \n                    \n                  \n                \n              \n            \n          \n        \n        \n          \n            \n              -0.6\n            \n          \n          \n            \n              -0.5\n            \n          \n          \n            \n              -0.4\n            \n          \n          \n            \n              -0.3\n            \n          \n          \n            \n              -0.2\n            \n          \n          \n            \n              -0.1\n            \n          \n          \n            \n              0.0\n            \n          \n          \n            \n              0.1\n            \n          \n          \n            \n              0.2\n            \n          \n          \n            \n              0.3\n            \n          \n          \n            \n              0.4\n            \n          \n          \n            \n              0.5\n            \n          \n          \n            \n              0.6\n            \n          \n          \n            \n              0.7\n            \n          \n          \n            \n              0.8\n            \n          \n          \n            \n              0.9\n            \n          \n          \n            \n              1.0\n            \n          \n          \n            \n              1.1\n            \n          \n          \n            \n              -0.50\n            \n          \n          \n            \n              -0.45\n            \n          \n          \n            \n              -0.40\n            \n          \n          \n            \n              -0.35\n            \n          \n          \n            \n              -0.30\n            \n          \n          \n            \n              -0.25\n            \n          \n          \n            \n              -0.20\n            \n          \n          \n            \n              -0.15\n            \n          \n          \n            \n              -0.10\n            \n          \n          \n            \n              -0.05\n            \n          \n          \n            \n              0.00\n            \n          \n          \n            \n              0.05\n            \n          \n          \n            \n              0.10\n            \n          \n          \n            \n              0.15\n            \n          \n          \n            \n              0.20\n            \n          \n          \n            \n              0.25\n            \n          \n          \n            \n              0.30\n            \n          \n          \n            \n              0.35\n            \n          \n          \n            \n              0.40\n            \n          \n          \n            \n              0.45\n            \n          \n          \n            \n              0.50\n            \n          \n          \n            \n              0.55\n            \n          \n          \n            \n              0.60\n            \n          \n          \n            \n              0.65\n            \n          \n          \n            \n              0.70\n            \n          \n          \n            \n              0.75\n            \n          \n          \n            \n              0.80\n            \n          \n          \n            \n              0.85\n            \n          \n          \n            \n              0.90\n            \n          \n          \n            \n              0.95\n            \n          \n          \n            \n              1.00\n            \n          \n          \n            \n              -0.5\n            \n          \n          \n            \n              0.0\n            \n          \n          \n            \n              0.5\n            \n          \n          \n            \n              1.0\n            \n          \n          \n            \n              -0.50\n            \n          \n          \n            \n              -0.48\n            \n          \n          \n            \n              -0.46\n            \n          \n          \n            \n              -0.44\n            \n          \n          \n            \n              -0.42\n            \n          \n          \n            \n              -0.40\n            \n          \n          \n            \n              -0.38\n            \n          \n          \n            \n              -0.36\n            \n          \n          \n            \n              -0.34\n            \n          \n          \n            \n              -0.32\n            \n          \n          \n            \n              -0.30\n            \n          \n          \n            \n              -0.28\n            \n          \n          \n            \n              -0.26\n            \n          \n          \n            \n              -0.24\n            \n          \n          \n            \n              -0.22\n            \n          \n          \n            \n              -0.20\n            \n          \n          \n            \n              -0.18\n            \n          \n          \n            \n              -0.16\n            \n          \n          \n            \n              -0.14\n            \n          \n          \n            \n              -0.12\n            \n          \n          \n            \n              -0.10\n            \n          \n          \n            \n              -0.08\n            \n          \n          \n            \n              -0.06\n            \n          \n          \n            \n              -0.04\n            \n          \n          \n            \n              -0.02\n            \n          \n          \n            \n              0.00\n            \n          \n          \n            \n              0.02\n            \n          \n          \n            \n              0.04\n            \n          \n          \n            \n              0.06\n            \n          \n          \n            \n              0.08\n            \n          \n          \n            \n              0.10\n            \n          \n          \n            \n              0.12\n            \n          \n          \n            \n              0.14\n            \n          \n          \n            \n              0.16\n            \n          \n          \n            \n              0.18\n            \n          \n          \n            \n              0.20\n            \n          \n          \n            \n              0.22\n            \n          \n          \n            \n              0.24\n            \n          \n          \n            \n              0.26\n            \n          \n          \n            \n              0.28\n            \n          \n          \n            \n              0.30\n            \n          \n          \n            \n              0.32\n            \n          \n          \n            \n              0.34\n            \n          \n          \n            \n              0.36\n            \n          \n          \n            \n              0.38\n            \n          \n          \n            \n              0.40\n            \n          \n          \n            \n              0.42\n            \n          \n          \n            \n              0.44\n            \n          \n          \n            \n              0.46\n            \n          \n          \n            \n              0.48\n            \n          \n          \n            \n              0.50\n            \n          \n          \n            \n              0.52\n            \n          \n          \n            \n              0.54\n            \n          \n          \n            \n              0.56\n            \n          \n          \n            \n              0.58\n            \n          \n          \n            \n              0.60\n            \n          \n          \n            \n              0.62\n            \n          \n          \n            \n              0.64\n            \n          \n          \n            \n              0.66\n            \n          \n          \n            \n              0.68\n            \n          \n          \n            \n              0.70\n            \n          \n          \n            \n              0.72\n            \n          \n          \n            \n              0.74\n            \n          \n          \n            \n              0.76\n            \n          \n          \n            \n              0.78\n            \n          \n          \n            \n              0.80\n            \n          \n          \n            \n              0.82\n            \n          \n          \n            \n              0.84\n            \n          \n          \n            \n              0.86\n            \n          \n          \n            \n              0.88\n            \n          \n          \n            \n              0.90\n            \n          \n          \n            \n              0.92\n            \n          \n          \n            \n              0.94\n            \n          \n          \n            \n              0.96\n            \n          \n          \n            \n              0.98\n            \n          \n          \n            \n              1.00\n            \n          \n        \n      \n    \n  \n  \n    \n      \n        Credibility\n      \n    \n  \n  \n    \n      \n        Prior\n      \n    \n  \n\n\n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n  \n    \n  \n\n\n\n\n\n\nmaybe add the annotation using something like below https://stackoverflow.com/questions/50925450/gadfly-julia-how-to-add-text-annotation-to-a-plot\n\n\n\nusing Gadfly\nusing Distributions\n\nset_default_plot_size(16cm, 18cm)\n\nd = Normal()\nσ = 2\nx1 = rand(Normal(1, σ), 10^5)\nx2 = rand(Normal(4, σ), 10^5)\nx3 = rand(Normal(7, σ), 10^5)\nx4 = rand(Normal(10, σ), 10^5)\nusing DataFrames\nx5 = DataFrame(Possibilities = 1, Credibility = 0.2)\nx6 = DataFrame(Possibilities = 4, Credibility = 0.2)\nx7 = DataFrame(Possibilities = 7, Credibility = 0.2)\nx8 = DataFrame(Possibilities = 10, Credibility = 0.2)\n\nplot(layer(x=x1, Geom.density, color=[\"auto\"]),\n    layer(x=x2, Geom.density, color=[\"auto\"]),\n    layer(x=x3, Geom.density, color=[\"auto\"]),\n    layer(x=x4, Geom.density, color=[\"auto\"]),\n    Guide.xlabel(\"Possibilities\"),\n    Guide.ylabel(\"Credibility\"),\n    Guide.title(\"Prior\"),\n    Theme(\n        background_color = \"white\",\n        grid_color = \"white\"\n    ),\n    layer(x5, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical)),\n    layer(x6, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical)),\n    layer(x7, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical)),\n    layer(x8, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical))   )\n    #found the correct way to do this!\n    # plot(layer(x->pdf(d, x), -4, 4, color=[colorant\"black\"]),\n    #  Theme(\n    #     background_color = \"white\",\n    #     grid_color = \"white\"\n    # ))\n\n\n\n\n\n\n  \n    \n  \n\n\n  \n    \n  \n\n\n  \n    \n      \n        Possibilities\n      \n    \n  \n  \n    \n      \n        -60\n      \n    \n    \n      \n        -50\n      \n    \n    \n      \n        -40\n      \n    \n    \n      \n        -30\n      \n    \n    \n      \n        -20\n      \n    \n    \n      \n        -10\n      \n    \n    \n      \n        0\n      \n    \n    \n      \n        10\n      \n    \n    \n      \n        20\n      \n    \n    \n      \n        30\n      \n    \n    \n      \n        40\n      \n    \n    \n      \n        50\n      \n    \n    \n      \n        60\n      \n    \n    \n      \n        70\n      \n    \n    \n      \n        80\n      \n    \n    \n      \n        -50\n      \n    \n    \n      \n        -45\n      \n    \n    \n      \n        -40\n      \n    \n    \n      \n        -35\n      \n    \n    \n      \n        -30\n      \n    \n    \n      \n        -25\n      \n    \n    \n      \n        -20\n      \n    \n    \n      \n        -15\n      \n    \n    \n      \n        -10\n      \n    \n    \n      \n        -5\n      \n    \n    \n      \n        0\n      \n    \n    \n      \n        5\n      \n    \n    \n      \n        10\n      \n    \n    \n      \n        15\n      \n    \n    \n      \n        20\n      \n    \n    \n      \n        25\n      \n    \n    \n      \n        30\n      \n    \n    \n      \n        35\n      \n    \n    \n      \n        40\n      \n    \n    \n      \n        45\n      \n    \n    \n      \n        50\n      \n    \n    \n      \n        55\n      \n    \n    \n      \n        60\n      \n    \n    \n      \n        65\n      \n    \n    \n      \n        70\n      \n    \n    \n      \n        -50\n      \n    \n    \n      \n        0\n      \n    \n    \n      \n        50\n      \n    \n    \n      \n        100\n      \n    \n    \n      \n        -50\n      \n    \n    \n      \n        -48\n      \n    \n    \n      \n        -46\n      \n    \n    \n      \n        -44\n      \n    \n    \n      \n        -42\n      \n    \n    \n      \n        -40\n      \n    \n    \n      \n        -38\n      \n    \n    \n      \n        -36\n      \n    \n    \n      \n        -34\n      \n    \n    \n      \n        -32\n      \n    \n    \n      \n        -30\n      \n    \n    \n      \n        -28\n      \n    \n    \n      \n        -26\n      \n    \n    \n      \n        -24\n      \n    \n    \n      \n        -22\n      \n    \n    \n      \n        -20\n      \n    \n    \n      \n        -18\n      \n    \n    \n      \n        -16\n      \n    \n    \n      \n        -14\n      \n    \n    \n      \n        -12\n      \n    \n    \n      \n        -10\n      \n    \n    \n      \n        -8\n      \n    \n    \n      \n        -6\n      \n    \n    \n      \n        -4\n      \n    \n    \n      \n        -2\n      \n    \n    \n      \n        0\n      \n    \n    \n      \n        2\n      \n    \n    \n      \n        4\n      \n    \n    \n      \n        6\n      \n    \n    \n      \n        8\n      \n    \n    \n      \n        10\n      \n    \n    \n      \n        12\n      \n    \n    \n      \n        14\n      \n    \n    \n      \n        16\n      \n    \n    \n      \n        18\n      \n    \n    \n      \n        20\n      \n    \n    \n      \n        22\n      \n    \n    \n      \n        24\n      \n    \n    \n      \n        26\n      \n    \n    \n      \n        28\n      \n    \n    \n      \n        30\n      \n    \n    \n      \n        32\n      \n    \n    \n      \n        34\n      \n    \n    \n      \n        36\n      \n    \n    \n      \n        38\n      \n    \n    \n      \n        40\n      \n    \n    \n      \n        42\n      \n    \n    \n      \n        44\n      \n    \n    \n      \n        46\n      \n    \n    \n      \n        48\n      \n    \n    \n      \n        50\n      \n    \n    \n      \n        52\n      \n    \n    \n      \n        54\n      \n    \n    \n      \n        56\n      \n    \n    \n      \n        58\n      \n    \n    \n      \n        60\n      \n    \n    \n      \n        62\n      \n    \n    \n      \n        64\n      \n    \n    \n      \n        66\n      \n    \n    \n      \n        68\n      \n    \n    \n      \n        70\n      \n    \n  \n  \n    \n      \n        \n          \n            auto\n          \n        \n      \n      \n        \n          \n        \n      \n    \n    \n      \n        \n          Color\n        \n      \n    \n  \n  \n    \n      \n        \n          \n        \n      \n      \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n      \n      \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n        \n          \n        \n      \n      \n        \n          \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n        \n          \n            \n              \n            \n          \n        \n      \n      \n        \n          \n            \n              \n            \n          \n        \n      \n      \n        \n          \n            \n              \n            \n          \n          \n            \n              \n                h,j,k,l,arrows,drag to pan\n              \n            \n            \n              \n                i,o,+,-,scroll,shift-drag to zoom\n              \n            \n            \n              \n                r,dbl-click to reset\n              \n            \n            \n              \n                c for coordinates\n              \n            \n            \n              \n                ? for help\n              \n            \n          \n        \n      \n      \n        \n          \n            \n              ?\n            \n          \n        \n      \n    \n  \n  \n    \n      \n        -0.30\n      \n    \n    \n      \n        -0.25\n      \n    \n    \n      \n        -0.20\n      \n    \n    \n      \n        -0.15\n      \n    \n    \n      \n        -0.10\n      \n    \n    \n      \n        -0.05\n      \n    \n    \n      \n        0.00\n      \n    \n    \n      \n        0.05\n      \n    \n    \n      \n        0.10\n      \n    \n    \n      \n        0.15\n      \n    \n    \n      \n        0.20\n      \n    \n    \n      \n        0.25\n      \n    \n    \n      \n        0.30\n      \n    \n    \n      \n        0.35\n      \n    \n    \n      \n        0.40\n      \n    \n    \n      \n        0.45\n      \n    \n    \n      \n        0.50\n      \n    \n    \n      \n        0.55\n      \n    \n    \n      \n        -0.26\n      \n    \n    \n      \n        -0.24\n      \n    \n    \n      \n        -0.22\n      \n    \n    \n      \n        -0.20\n      \n    \n    \n      \n        -0.18\n      \n    \n    \n      \n        -0.16\n      \n    \n    \n      \n        -0.14\n      \n    \n    \n      \n        -0.12\n      \n    \n    \n      \n        -0.10\n      \n    \n    \n      \n        -0.08\n      \n    \n    \n      \n        -0.06\n      \n    \n    \n      \n        -0.04\n      \n    \n    \n      \n        -0.02\n      \n    \n    \n      \n        0.00\n      \n    \n    \n      \n        0.02\n      \n    \n    \n      \n        0.04\n      \n    \n    \n      \n        0.06\n      \n    \n    \n      \n        0.08\n      \n    \n    \n      \n        0.10\n      \n    \n    \n      \n        0.12\n      \n    \n    \n      \n        0.14\n      \n    \n    \n      \n        0.16\n      \n    \n    \n      \n        0.18\n      \n    \n    \n      \n        0.20\n      \n    \n    \n      \n        0.22\n      \n    \n    \n      \n        0.24\n      \n    \n    \n      \n        0.26\n      \n    \n    \n      \n        0.28\n      \n    \n    \n      \n        0.30\n      \n    \n    \n      \n        0.32\n      \n    \n    \n      \n        0.34\n      \n    \n    \n      \n        0.36\n      \n    \n    \n      \n        0.38\n      \n    \n    \n      \n        0.40\n      \n    \n    \n      \n        0.42\n      \n    \n    \n      \n        0.44\n      \n    \n    \n      \n        0.46\n      \n    \n    \n      \n        0.48\n      \n    \n    \n      \n        0.50\n      \n    \n    \n      \n        -0.25\n      \n    \n    \n      \n        0.00\n      \n    \n    \n      \n        0.25\n      \n    \n    \n      \n        0.50\n      \n    \n    \n      \n        -0.25\n      \n    \n    \n      \n        -0.24\n      \n    \n    \n      \n        -0.23\n      \n    \n    \n      \n        -0.22\n      \n    \n    \n      \n        -0.21\n      \n    \n    \n      \n        -0.20\n      \n    \n    \n      \n        -0.19\n      \n    \n    \n      \n        -0.18\n      \n    \n    \n      \n        -0.17\n      \n    \n    \n      \n        -0.16\n      \n    \n    \n      \n        -0.15\n      \n    \n    \n      \n        -0.14\n      \n    \n    \n      \n        -0.13\n      \n    \n    \n      \n        -0.12\n      \n    \n    \n      \n        -0.11\n      \n    \n    \n      \n        -0.10\n      \n    \n    \n      \n        -0.09\n      \n    \n    \n      \n        -0.08\n      \n    \n    \n      \n        -0.07\n      \n    \n    \n      \n        -0.06\n      \n    \n    \n      \n        -0.05\n      \n    \n    \n      \n        -0.04\n      \n    \n    \n      \n        -0.03\n      \n    \n    \n      \n        -0.02\n      \n    \n    \n      \n        -0.01\n      \n    \n    \n      \n        0.00\n      \n    \n    \n      \n        0.01\n      \n    \n    \n      \n        0.02\n      \n    \n    \n      \n        0.03\n      \n    \n    \n      \n        0.04\n      \n    \n    \n      \n        0.05\n      \n    \n    \n      \n        0.06\n      \n    \n    \n      \n        0.07\n      \n    \n    \n      \n        0.08\n      \n    \n    \n      \n        0.09\n      \n    \n    \n      \n        0.10\n      \n    \n    \n      \n        0.11\n      \n    \n    \n      \n        0.12\n      \n    \n    \n      \n        0.13\n      \n    \n    \n      \n        0.14\n      \n    \n    \n      \n        0.15\n      \n    \n    \n      \n        0.16\n      \n    \n    \n      \n        0.17\n      \n    \n    \n      \n        0.18\n      \n    \n    \n      \n        0.19\n      \n    \n    \n      \n        0.20\n      \n    \n    \n      \n        0.21\n      \n    \n    \n      \n        0.22\n      \n    \n    \n      \n        0.23\n      \n    \n    \n      \n        0.24\n      \n    \n    \n      \n        0.25\n      \n    \n    \n      \n        0.26\n      \n    \n    \n      \n        0.27\n      \n    \n    \n      \n        0.28\n      \n    \n    \n      \n        0.29\n      \n    \n    \n      \n        0.30\n      \n    \n    \n      \n        0.31\n      \n    \n    \n      \n        0.32\n      \n    \n    \n      \n        0.33\n      \n    \n    \n      \n        0.34\n      \n    \n    \n      \n        0.35\n      \n    \n    \n      \n        0.36\n      \n    \n    \n      \n        0.37\n      \n    \n    \n      \n        0.38\n      \n    \n    \n      \n        0.39\n      \n    \n    \n      \n        0.40\n      \n    \n    \n      \n        0.41\n      \n    \n    \n      \n        0.42\n      \n    \n    \n      \n        0.43\n      \n    \n    \n      \n        0.44\n      \n    \n    \n      \n        0.45\n      \n    \n    \n      \n        0.46\n      \n    \n    \n      \n        0.47\n      \n    \n    \n      \n        0.48\n      \n    \n    \n      \n        0.49\n      \n    \n    \n      \n        0.50\n      \n    \n  \n  \n    \n      \n        Credibility\n      \n    \n  \n  \n    \n      \n        Prior"
  },
  {
    "objectID": "introduction-credibility-models-and-parameters.html#possibilities-are-parameter-values-in-descriptive-models",
    "href": "introduction-credibility-models-and-parameters.html#possibilities-are-parameter-values-in-descriptive-models",
    "title": "2  Introduction: Credibility, Models, and Parameters",
    "section": "2.2 Possibilities are parameter values in descriptive models",
    "text": "2.2 Possibilities are parameter values in descriptive models"
  },
  {
    "objectID": "introduction-credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis",
    "href": "introduction-credibility-models-and-parameters.html#the-steps-of-bayesian-data-analysis",
    "title": "2  Introduction: Credibility, Models, and Parameters",
    "section": "2.3 The steps of Bayesian data analysis",
    "text": "2.3 The steps of Bayesian data analysis\n\nIn general, Bayesian analysis of data follows these steps:\n\nIdentify the data relevant to the research questions. What are the measurement scales of the data? Which data variables are to be predicted, and which data variables are supposed to act as predictors?\nDefine a descriptive model for the relevant data. The mathematical form and its parameters should be meaningful and appropriate to the theoretical purposes of the analysis.\nSpecify a prior distribution on the parameters. The prior must pass muster with the audience of the analysis, such as skeptical scientists.\nUse Bayesian inference to re-allocate credibility across parameter values. Interpret the posterior distribution with respect to theoretically meaningful issues (assuming that the model is a reasonable description of the data; see next step).\nCheck that the posterior predictions mimic the data with reasonable accuracy (i.e., conduct a “posterior predictive check”). If not, then consider a different descriptive model.\n\nPerhaps the best way to explain these steps is with a realistic example of Bayesian data analysis. The discussion that follows is abbreviated for purposes of this introductory chapter, with many technical details suppressed. (p. 25)\n\nI will showcase the entire workflow here. In later chapters we’ll cover this workflow in much more detail.\nFirst we need to generate the data and fit a model to those data. In HtWtDataDenerator.R script, Kruschke provided the code for a function that will simulate height/weight data. Lets rewrite that function in Julia:\n\nusing Distributions, Random, DataFrames, StatsBase\n\nfunction HtWtDataGenerator(nSubj, rndsd = nothing, maleProb = 0.50) \n    # Random height, weight generator for males and females. Uses parameters from\n    # Brainard, J. & Burmaster, D. E. (1992). Bivariate distributions for height and\n    # weight of men and women in the United States. Risk Analysis, 12(2), 267-275.\n    # Kruschke, J. K. (2011). Doing Bayesian data analysis:\n    # A Tutorial with R and BUGS. Academic Press / Elsevier.\n    # Kruschke, J. K. (2014). Doing Bayesian data analysis, 2nd Edition:\n    # A Tutorial with R, JAGS and Stan. Academic Press / Elsevier.\n    \n    # Specify parameters of multivariate normal (MVN) distributions.\n  \n    # Men:\n    HtMmu   = 69.18\n    HtMsd   = 2.87\n    lnWtMmu = 5.14\n    lnWtMsd = 0.17\n    Mrho    = 0.42\n    Mmean   = [HtMmu, lnWtMmu]\n    Msigma  = [HtMsd^2 Mrho * HtMsd * lnWtMsd; Mrho * HtMsd * lnWtMsd lnWtMsd^2]\n    # Women cluster 1:\n    HtFmu1   = 63.11\n    HtFsd1   = 2.76\n    lnWtFmu1 = 5.06\n    lnWtFsd1 = 0.24\n    Frho1    = 0.41\n    prop1    = 0.46\n    Fmean1   = [HtFmu1, lnWtFmu1]\n    Fsigma1  = [HtFsd1^2 Frho1 * HtFsd1 * lnWtFsd1; Frho1 * HtFsd1 * lnWtFsd1  lnWtFsd1^2]\n    # Women cluster 2:\n    HtFmu2   = 64.36\n    HtFsd2   = 2.49\n    lnWtFmu2 = 4.86\n    lnWtFsd2 = 0.14\n    Frho2    = 0.44\n    prop2    = 1 - prop1\n    Fmean2   = [HtFmu2, lnWtFmu2]\n    Fsigma2  = [HtFsd2^2  Frho2 * HtFsd2 * lnWtFsd2; Frho2 * HtFsd2 * lnWtFsd2  lnWtFsd2^2]\n\n    # Randomly generate data values from those MVN distributions.\n    if rndsd !== nothing \n        Random.seed!(rndsd) \n    end\n    datamatrix =  DataFrame(zeros(nSubj, 3), [\"male\", \"height\", \"weight\"])\n    # arbitrary coding values\n    maleval = 1\n    femaleval = 0\n\n    for i in 1:nSubj\n        # Flip coin to decide sex\n        sex = wsample([maleval, femaleval], [maleProb, 1 - maleProb], 1)\n\n        if sex[1] == maleval\n            datum = rand(MvNormal(Mmean, Msigma))\n        elseif sex[1] == femaleval\n            Fclust = wsample([1, 2], [prop1, prop2], 1)\n\n            if Fclust[1] == 1\n            datum = rand(MvNormal(Fmean1, Fsigma1))\n            else\n            datum = rand(MvNormal(Fmean2, Fsigma2))\n            end\n        end\n        datum[2] = exp(datum[2])\n        datamatrix[i, :] = [sex; round.(datum, digits = 1)]\n    end\n\n    return datamatrix\n\nend\n\nHtWtDataGenerator (generic function with 3 methods)\n\n\nThe HtWtDataGenerator() function has two arguments. The nSubj argument determines how many values to generate, and maleProb determines how probable we want those values to be from men.\n\n\n\n5 rows × 3 columnsmaleheightweightFloat64Float64Float6411.066.0141.220.060.4104.330.062.7139.440.061.7109.951.064.4162.5\n\n\nWe’re about ready for the model, which we will fit it with the Hamiltonian Monte Carlo (HMC) method via the turing.jl package. We’ll introduce turing.jl more fully in Chapter 8. I also recommend you go check out the following and resources:\n\nhttps://turing.ml/v0.21/tutorials/00-introduction/\nhttp://hakank.org/julia/turing/\nhttps://storopoli.github.io/Bayesian-Julia/\n\n\nusing Turing\nusing Optim\nusing MCMCChains, Plots, StatsPlots, Gadfly\nusing AbstractMCMC\n# Define the model\n# linear regression.\n@model function linear_regression(x,y)\n    n = length(y)\n\n    # Set variance prior.\n    σ ~  Truncated(Cauchy(0,10),0,Inf)\n    # Set intercept prior.\n    α ~ Normal(0,100)\n    #α ~ Truncated(Normal(0,1000),0)\n    # Set the prior for beta.\n    β  ~ Normal(0,100)\n\n    for i in 1:n\n        y[i] ~ Normal(α + β * x[i], σ)\n    end\n\n    return y\nend\n\n#to be concrete we assign the values to x and y\nx = d.height\ny = d.weight\n\nmodel = linear_regression(x, y)\n\n#  Run sampler, collect results\nchain_lin_reg = sample(model, NUTS(500, 0.65),MCMCDistributed(),2_000, 4);\n\n# Summarise results\ndisplay(chain_lin_reg)\n\nmean(chain_lin_reg[:β]) # Taking the mean of a variable\nhistogram(chain_lin_reg[:σ])\nquantile(chain_lin_reg)\n\n# Plot and save results\np = Plots.plot(chain_lin_reg)\n\n# extract the posterior draws\n# model_pred = linear_regression(x,Vector{Missing}(missing, length(y)))\n# posterior_check = predict(model_pred, chain_lin_reg)\n\n# set_default_plot_size(16cm, 18cm)\n\n# chain_lin_reg[:,:β,:1]\n# chain_lin_reg[:,:α,:1]\n\n# plot_df = DataFrame(inter = sample(chain_lin_reg[:,:α,:1], 57), beta = sample(chain_lin_reg[:,:β,:1], 57), x = x, y = y)\n\n# abline = Geom.abline(color=\"red\", style=:dash)\n\n# Gadfly.plot(plot_df, x=:x, y=:y, Geom.point, intercept=[inter[1]], slope=[beta[1]],abline)\n\n# chain_lin_reg\n# inter = sample(chain_lin_reg[:,:α,:1], 10)\n# beta = sample(chain_lin_reg[:,:β,:1], 10)\n\n# Gadfly.plot(plot_df, x=:x, y=:y, Geom.point, intercept=[inter[1]], slope=[beta[1]],abline)\n\nWARNING: using Plots.plot in module Main conflicts with an existing identifier.\n┌ Warning: Only a single process available: MCMC chains are not sampled in parallel\n└ @ AbstractMCMC /Users/kiantefernandez/.julia/packages/AbstractMCMC/fnRmh/src/sample.jl:400\n┌ Info: Found initial step size\n│   ϵ = 0.0125\n└ @ Turing.Inference /Users/kiantefernandez/.julia/packages/Turing/szPqN/src/inference/hmc.jl:191\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Info: Found initial step size\n│   ϵ = 0.003125\n└ @ Turing.Inference /Users/kiantefernandez/.julia/packages/Turing/szPqN/src/inference/hmc.jl:191\nSampling (1 processes):  50%|█████████████▌             |  ETA: 0:00:01┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n\n\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Info: Found initial step size\n│   ϵ = 0.0001953125\n└ @ Turing.Inference /Users/kiantefernandez/.julia/packages/Turing/szPqN/src/inference/hmc.jl:191\nSampling (1 processes):  75%|████████████████████▎      |  ETA: 0:00:01┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n\n\n┌ Warning: The current proposal will be rejected due to numerical error(s).\n│   isfinite.((θ, r, ℓπ, ℓκ)) = (true, false, false, false)\n└ @ AdvancedHMC /Users/kiantefernandez/.julia/packages/AdvancedHMC/51xgc/src/hamiltonian.jl:47\n┌ Info: Found initial step size\n│   ϵ = 0.0001953125\n└ @ Turing.Inference /Users/kiantefernandez/.julia/packages/Turing/szPqN/src/inference/hmc.jl:191\nSampling (1 processes): 100%|███████████████████████████| Time: 0:00:03\n\n\n\nChains MCMC chain (2000×15×4 Array{Float64, 3}):\nIterations        = 501:1:2500\nNumber of chains  = 4\nSamples per chain = 2000\nWall duration     = 17.49 seconds\nCompute duration  = 14.01 seconds\nparameters        = σ, α, β\ninternals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size\nSummary Statistics\n  parameters        mean       std   naive_se      mcse         ess      rhat  ⋯\n      Symbol     Float64   Float64    Float64   Float64     Float64   Float64  ⋯\n           σ     27.3310    2.7192     0.0304    0.0462   3225.0787    1.0004  ⋯\n           α   -221.9686   53.7895     0.6014    1.0474   2553.6841    1.0009  ⋯\n           β      5.7629    0.8101     0.0091    0.0158   2547.6956    1.0008  ⋯\n                                                                1 column omitted\nQuantiles\n  parameters        2.5%       25.0%       50.0%       75.0%       97.5% \n      Symbol     Float64     Float64     Float64     Float64     Float64 \n           σ     22.5904     25.4454     27.0657     29.0050     33.3667\n           α   -323.7305   -258.5197   -223.1791   -186.1666   -110.4314\n           β      4.0894      5.2241      5.7858      6.3118      7.3058\n\n\n\n\n\n\n\n\n# res = quantile(posterior_check)\n\n# describe(DataFrame(summarystats(posterior_check)))\n# plot(res[:,4])\n\n# plot!\n\n# set_default_plot_size(16cm, 18cm)\n# n_lines = 150\n# D = DataFrame(x = x, y = res[:,4], y2 = res[:,6], y3 = res[:,2], yt = y)\n# p = Gadfly.plot(D, x=:x, y=:y, Geom.point,\n#   layer(Stat.smooth(method=:lm), Geom.line, Geom.ribbon(fill=false)),\n#   layer(x=:x, y=:y2, Geom.line, color=[\"grey\"]),\n#   layer(x=:x, y=:y3, Geom.line, color=[\"grey\"]),\n#   layer(x=:x, y=:yt, Geom.point, color=[\"red\"]),\n#     Guide.xlabel(\"Height in inches\"),\n#     Guide.ylabel(\"Weight in pounds\"),\n#     Guide.title(\"Data with the percentile-based 95% intervals and\\nthe means of the posterior predictions\"),\n#      Theme(background_color = \"white\",\n#      grid_color = \"white\", line_style=[:solid, :dot])\n#     )"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bezanson, Jeff, Alan Edelman, Stefan Karpinski, and Viral B Shah. 2017.\n“Julia: A Fresh Approach to Numerical Computing.” SIAM\nReview 59 (1): 65–98. https://doi.org/10.1137/141000671.\n\n\nGe, Hong, Kai Xu, and Zoubin Ghahramani. 2018. “Turing: A Language\nfor Flexible Probabilistic Inference.” In International\nConference on Artificial Intelligence and Statistics,\nAISTATS 2018, 9-11 April 2018, Playa Blanca, Lanzarote,\nCanary Islands, Spain, 1682–90. http://proceedings.mlr.press/v84/ge18b.html.\n\n\nKruschke, John. 2015. Doing Bayesian Data Analysis (Second\nEdition). Boston: Academic Press."
  }
]