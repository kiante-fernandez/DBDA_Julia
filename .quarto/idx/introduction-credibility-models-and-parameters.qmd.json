{"title":"Introduction: Credibility, Models, and Parameters","markdown":{"yaml":{"format":{"html":{"code-fold":false}},"jupyter":"julia-1.7"},"headingText":"Introduction: Credibility, Models, and Parameters","containsRefs":false,"markdown":"\n\n\n## Bayesian inference is reallocation of credibility across possibilities\n\nTo make Figure 2.1 we need data. We will create some synthetic data and store it in using `DataFrames.jl`\n\n```{julia}\n#| warning: false\n#| output: false\n\nusing DataFrames\n\nfunction expand_grid(; iters...)\n    var_names = collect(keys(iters))\n    var_itr = [1:length(x) for x in iters.data]\n    var_ix = vcat([collect(x)' for x in Iterators.product(var_itr...)]...)\n    out = DataFrame()\n    for i = 1:length(var_names)\n        out[:,var_names[i]] = collect(iters[i])[var_ix[:,i]]\n    end\n    return out\nend\n\nd = expand_grid(iteration=1:3, Possibilities=[\"A\", \"B\",\"C\", \"D\"], stage = [\"Prior\", \"Posterior\"])\n\nd2 =DataFrame(Credibility =[fill(.25,4); 0; fill(1/3,3); 0; fill(1/3,3);0;.5;0;0.5;0;.5;0;0.5;fill(0,3);1])\n\nsort!(d, [:iteration])\nd.Credibility = d2.Credibility\n\n```\n\nHere we are defining a function that creates combinations and then I just bind that we the Credibility values we will use for plotting. \n\nWe can take a look at the top few rows of the data with the `first()` function.\n\n```{julia}\nfirst(d,5)\n```\n\nNow lets plot our version of Figure 2.1. To do so, we will use the `Gadfly.jl` package. This is my preferred plotting package because it has similar syntax to ggplot2 package in R.\n\n\n```{julia}\n#| warning: false\n#| echo: false\n\nusing Gadfly\nusing DataFramesMeta\n\n#Specify the plot size\nset_default_plot_size(16cm, 18cm)\n\ndf_Prior = @where(d, :stage .== \"Prior\")\ndf_Posterior = @where(d, :stage .== \"Posterior\")\n\nfig1a = plot(df_Prior,\n    xgroup = :iteration,\n    x = :Possibilities,\n    y = :Credibility,\n    Geom.subplot_grid(Geom.bar(orientation = :vertical),\n    Guide.xlabel(orientation= :horizontal),\n    Guide.xticks(orientation = :horizontal)),\n    Guide.xlabel(\"Possibilities\"),\n    Guide.ylabel(\"Credibility\"),\n    Guide.title(\"Prior\"),\n    Scale.y_continuous(format = :plain),\n    Theme(\n        background_color = \"white\",\n        bar_spacing = 1mm,\n        grid_color = \"white\"\n    )\n)\nfig1b = plot(df_Posterior,\n    xgroup = :iteration,\n    x = :Possibilities,\n    y = :Credibility,\n    Geom.subplot_grid(Geom.bar(orientation = :vertical),\n    Guide.xlabel(orientation= :horizontal),\n    Guide.xticks(orientation = :horizontal)),\n    Guide.xlabel(\"Possibilities\"),\n    Guide.ylabel(\"Credibility\"),\n    Guide.title(\"Posterior\"),\n    Scale.y_continuous(format = :plain),\n    Theme(\n        background_color = \"white\",\n        bar_spacing = 1mm,\n        grid_color = \"white\"\n    )\n)\n#create a subplot\nvstack(fig1a,fig1b)\n```\n\nmaybe add the annotation using something like below\nhttps://stackoverflow.com/questions/50925450/gadfly-julia-how-to-add-text-annotation-to-a-plot\n\n### Data are noisy and inferences are probabilistic.\n\n```{julia}\nusing Gadfly\nusing Distributions\n\nset_default_plot_size(16cm, 18cm)\n\nd = Normal()\nσ = 2\nx1 = rand(Normal(1, σ), 10^5)\nx2 = rand(Normal(4, σ), 10^5)\nx3 = rand(Normal(7, σ), 10^5)\nx4 = rand(Normal(10, σ), 10^5)\nusing DataFrames\nx5 = DataFrame(Possibilities = 1, Credibility = 0.2)\nx6 = DataFrame(Possibilities = 4, Credibility = 0.2)\nx7 = DataFrame(Possibilities = 7, Credibility = 0.2)\nx8 = DataFrame(Possibilities = 10, Credibility = 0.2)\n\nplot(layer(x=x1, Geom.density, color=[\"auto\"]),\n    layer(x=x2, Geom.density, color=[\"auto\"]),\n    layer(x=x3, Geom.density, color=[\"auto\"]),\n    layer(x=x4, Geom.density, color=[\"auto\"]),\n    Guide.xlabel(\"Possibilities\"),\n    Guide.ylabel(\"Credibility\"),\n    Guide.title(\"Prior\"),\n    Theme(\n        background_color = \"white\",\n        grid_color = \"white\"\n    ),\n    layer(x5, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical)),\n    layer(x6, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical)),\n    layer(x7, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical)),\n    layer(x8, x = :Possibilities, y = :Credibility, Geom.bar(orientation = :vertical))   )\n    #found the correct way to do this!\n    # plot(layer(x->pdf(d, x), -4, 4, color=[colorant\"black\"]),\n    #  Theme(\n    #     background_color = \"white\",\n    #     grid_color = \"white\"\n    # ))\n\n\n```\n\n## Possibilities are parameter values in descriptive models\n\n## The steps of Bayesian data analysis\n\n> In general, Bayesian analysis of data follows these steps:\n>\n> 1. Identify the data relevant to the research questions. What are the measurement scales of the data? Which data variables are to be predicted, and which data variables are supposed to act as predictors?\n> 2. Define a descriptive model for the relevant data. The mathematical form and its parameters should be meaningful and appropriate to the theoretical purposes of the analysis.\n> 3. Specify a prior distribution on the parameters. The prior must pass muster with the audience of the analysis, such as skeptical scientists.\n> 4. Use Bayesian inference to re-allocate credibility across parameter values. Interpret the posterior distribution with respect to theoretically meaningful issues (assuming that the model is a reasonable description of the data; see next step).\n> 5. Check that the posterior predictions mimic the data with reasonable accuracy (i.e., conduct a “posterior predictive check”). If not, then consider a different descriptive model.\n>\n> Perhaps the best way to explain these steps is with a realistic example of Bayesian data analysis. The discussion that follows is abbreviated for purposes of this introductory chapter, with many technical details suppressed. (p. 25)\n\nI will showcase the entire workflow here. In later chapters we’ll cover this workflow in much more detail. \n\nFirst we need to generate the data and fit a model to those data. In `HtWtDataDenerator.R` script, Kruschke provided the code for a function that will simulate height/weight data. Lets rewrite that function in Julia:\n\n```{julia}\nusing Distributions, Random, DataFrames, StatsBase\n\nfunction HtWtDataGenerator(nSubj, rndsd = nothing, maleProb = 0.50) \n    # Random height, weight generator for males and females. Uses parameters from\n    # Brainard, J. & Burmaster, D. E. (1992). Bivariate distributions for height and\n    # weight of men and women in the United States. Risk Analysis, 12(2), 267-275.\n    # Kruschke, J. K. (2011). Doing Bayesian data analysis:\n    # A Tutorial with R and BUGS. Academic Press / Elsevier.\n    # Kruschke, J. K. (2014). Doing Bayesian data analysis, 2nd Edition:\n    # A Tutorial with R, JAGS and Stan. Academic Press / Elsevier.\n    \n    # Specify parameters of multivariate normal (MVN) distributions.\n  \n    # Men:\n    HtMmu   = 69.18\n    HtMsd   = 2.87\n    lnWtMmu = 5.14\n    lnWtMsd = 0.17\n    Mrho    = 0.42\n    Mmean   = [HtMmu, lnWtMmu]\n    Msigma  = [HtMsd^2 Mrho * HtMsd * lnWtMsd; Mrho * HtMsd * lnWtMsd lnWtMsd^2]\n    # Women cluster 1:\n    HtFmu1   = 63.11\n    HtFsd1   = 2.76\n    lnWtFmu1 = 5.06\n    lnWtFsd1 = 0.24\n    Frho1    = 0.41\n    prop1    = 0.46\n    Fmean1   = [HtFmu1, lnWtFmu1]\n    Fsigma1  = [HtFsd1^2 Frho1 * HtFsd1 * lnWtFsd1; Frho1 * HtFsd1 * lnWtFsd1  lnWtFsd1^2]\n    # Women cluster 2:\n    HtFmu2   = 64.36\n    HtFsd2   = 2.49\n    lnWtFmu2 = 4.86\n    lnWtFsd2 = 0.14\n    Frho2    = 0.44\n    prop2    = 1 - prop1\n    Fmean2   = [HtFmu2, lnWtFmu2]\n    Fsigma2  = [HtFsd2^2  Frho2 * HtFsd2 * lnWtFsd2; Frho2 * HtFsd2 * lnWtFsd2  lnWtFsd2^2]\n\n    # Randomly generate data values from those MVN distributions.\n    if rndsd !== nothing \n        Random.seed!(rndsd) \n    end\n    datamatrix =  DataFrame(zeros(nSubj, 3), [\"male\", \"height\", \"weight\"])\n    # arbitrary coding values\n    maleval = 1\n    femaleval = 0\n\n    for i in 1:nSubj\n        # Flip coin to decide sex\n        sex = wsample([maleval, femaleval], [maleProb, 1 - maleProb], 1)\n\n        if sex[1] == maleval\n            datum = rand(MvNormal(Mmean, Msigma))\n        elseif sex[1] == femaleval\n            Fclust = wsample([1, 2], [prop1, prop2], 1)\n\n            if Fclust[1] == 1\n            datum = rand(MvNormal(Fmean1, Fsigma1))\n            else\n            datum = rand(MvNormal(Fmean2, Fsigma2))\n            end\n        end\n        datum[2] = exp(datum[2])\n        datamatrix[i, :] = [sex; round.(datum, digits = 1)]\n    end\n\n    return datamatrix\n\nend\n```\n\nThe `HtWtDataGenerator()` function has two arguments. The nSubj argument determines how many values to generate, and  maleProb determines how probable we want those values to be from men.\n\n```{julia}\n#| warning: false\n#| echo: false\n\n# set your seed to make the data generation reproducible\nRandom.seed!(2022) \n\nd = HtWtDataGenerator(57, 2022, 0.5)\n\nfirst(d,5)\n```\n\nWe’re about ready for the model, which we will fit it with the Hamiltonian Monte Carlo (HMC) method via the turing.jl package. We’ll introduce turing.jl more fully in Chapter 8. I also recommend you go check out the following and resources:\n\n- [https://turing.ml/v0.21/tutorials/00-introduction/](https://turing.ml/v0.21/tutorials/00-introduction/)\n- [http://hakank.org/julia/turing/](http://hakank.org/julia/turing/)\n- [https://storopoli.github.io/Bayesian-Julia/](https://storopoli.github.io/Bayesian-Julia/)\n\n```{julia}\nusing Turing\nusing Optim\nusing MCMCChains, Plots, StatsPlots, Gadfly\nusing AbstractMCMC\n# Define the model\n# linear regression.\n@model function linear_regression(x,y)\n    n = length(y)\n\n    # Set variance prior.\n    σ ~  Truncated(Cauchy(0,10),0,Inf)\n    # Set intercept prior.\n    α ~ Normal(0,100)\n    #α ~ Truncated(Normal(0,1000),0)\n    # Set the prior for beta.\n    β  ~ Normal(0,100)\n\n    for i in 1:n\n        y[i] ~ Normal(α + β * x[i], σ)\n    end\n\n    return y\nend\n\n#to be concrete we assign the values to x and y\nx = d.height\ny = d.weight\n\nmodel = linear_regression(x, y)\n\n#  Run sampler, collect results\nchain_lin_reg = sample(model, NUTS(500, 0.65),MCMCDistributed(),2_000, 4);\n\n# Summarise results\ndisplay(chain_lin_reg)\n\nmean(chain_lin_reg[:β]) # Taking the mean of a variable\nhistogram(chain_lin_reg[:σ])\nquantile(chain_lin_reg)\n\n# Plot and save results\np = Plots.plot(chain_lin_reg)\n\n# extract the posterior draws\n# model_pred = linear_regression(x,Vector{Missing}(missing, length(y)))\n# posterior_check = predict(model_pred, chain_lin_reg)\n\n# set_default_plot_size(16cm, 18cm)\n\n# chain_lin_reg[:,:β,:1]\n# chain_lin_reg[:,:α,:1]\n\n# plot_df = DataFrame(inter = sample(chain_lin_reg[:,:α,:1], 57), beta = sample(chain_lin_reg[:,:β,:1], 57), x = x, y = y)\n\n# abline = Geom.abline(color=\"red\", style=:dash)\n\n# Gadfly.plot(plot_df, x=:x, y=:y, Geom.point, intercept=[inter[1]], slope=[beta[1]],abline)\n\n# chain_lin_reg\n# inter = sample(chain_lin_reg[:,:α,:1], 10)\n# beta = sample(chain_lin_reg[:,:β,:1], 10)\n\n# Gadfly.plot(plot_df, x=:x, y=:y, Geom.point, intercept=[inter[1]], slope=[beta[1]],abline)\n\n```\n\n\n\n```{julia}\n\n\n# res = quantile(posterior_check)\n\n# describe(DataFrame(summarystats(posterior_check)))\n# plot(res[:,4])\n\n# plot!\n\n# set_default_plot_size(16cm, 18cm)\n# n_lines = 150\n# D = DataFrame(x = x, y = res[:,4], y2 = res[:,6], y3 = res[:,2], yt = y)\n# p = Gadfly.plot(D, x=:x, y=:y, Geom.point,\n#   layer(Stat.smooth(method=:lm), Geom.line, Geom.ribbon(fill=false)),\n#   layer(x=:x, y=:y2, Geom.line, color=[\"grey\"]),\n#   layer(x=:x, y=:y3, Geom.line, color=[\"grey\"]),\n#   layer(x=:x, y=:yt, Geom.point, color=[\"red\"]),\n#     Guide.xlabel(\"Height in inches\"),\n#     Guide.ylabel(\"Weight in pounds\"),\n#     Guide.title(\"Data with the percentile-based 95% intervals and\\nthe means of the posterior predictions\"),\n#      Theme(background_color = \"white\",\n#      grid_color = \"white\", line_style=[:solid, :dot])\n#     )\n\n```\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":true,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"introduction-credibility-models-and-parameters.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.38","bibliography":["references.bib"],"theme":"cosmo","cover-image":"DBDA2Ecover.png","jupyter":"julia-1.7"},"extensions":{"book":{"multiFile":true}}}}}